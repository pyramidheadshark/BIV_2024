{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ÐšÐ»Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ð½Ð¸Ñ**"
      ],
      "metadata": {
        "id": "ERVpzUU15dHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pyramidheadshark/BIV_2024.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HdrzzMB_SCf",
        "outputId": "8345eb86-8f99-4e34-bb6e-e80e1d498b9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BIV_2024'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 130 (delta 49), reused 110 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 22.27 MiB | 14.22 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('BIV_2024')\n",
        "os.system('git checkout bert')\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv4-VPlj_TqM",
        "outputId": "4c51e34e-e823-4e38-bb8d-ce2c3a59f3e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models', 'notebooks', 'data', 'src', '.gitignore', '.git']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ð¢Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸"
      ],
      "metadata": {
        "id": "5rJCoFww6cNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets > None\n",
        "!pip install onnxruntime > None\n",
        "!pip install optimum > None\n",
        "!pip install onnx > None"
      ],
      "metadata": {
        "id": "O3iouAcV_gn-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/models_dev/train.py \\\n",
        "                   --file_path data/processed/payments_categorized_v3.tsv\\\n",
        "                   --model_name cointegrated/rubert-tiny2 \\\n",
        "                   --output_dir ./results \\\n",
        "                   --batch_size 128 \\\n",
        "                   --epochs 5 \\\n",
        "                   --learning_rate 5e-5 \\\n",
        "                   --save_path models/trained_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O_yfckW_975",
        "outputId": "c1da71b1-8f2d-44fe-87e4-e84d053ac07d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 17:06:24.201590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-16 17:06:24.229577: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-16 17:06:24.235538: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-16 17:06:24.249853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-16 17:06:25.431457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/BIV_2024/src/models_dev/train.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['category'] = df['category'].astype('category').cat.codes\n",
            "/content/BIV_2024/src/models_dev/train.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['category'] = df['category'].astype('category').cat.codes\n",
            "tokenizer_config.json: 100% 401/401 [00:00<00:00, 2.25MB/s]\n",
            "vocab.txt: 100% 1.08M/1.08M [00:00<00:00, 2.55MB/s]\n",
            "tokenizer.json: 100% 1.74M/1.74M [00:00<00:00, 7.09MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 773kB/s]\n",
            "config.json: 100% 693/693 [00:00<00:00, 4.78MB/s]\n",
            "model.safetensors: 100% 118M/118M [00:00<00:00, 225MB/s] \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100% 14243/14243 [00:02<00:00, 7010.23 examples/s]\n",
            "Map: 100% 3561/3561 [00:00<00:00, 7339.34 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/content/BIV_2024/src/models_dev/train.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            " 18% 99/560 [00:10<00:39, 11.62it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:00, 48.78it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 40.74it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 39.64it/s]\u001b[A\n",
            " 71% 20/28 [00:00<00:00, 39.26it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 1.1889537572860718, 'eval_accuracy': 0.6478517270429655, 'eval_f1': 0.5921059326778787, 'eval_runtime': 0.7657, 'eval_samples_per_second': 4650.523, 'eval_steps_per_second': 36.567, 'epoch': 0.89}\n",
            " 18% 100/560 [00:11<00:39, 11.62it/s]\n",
            "100% 28/28 [00:00<00:00, 38.74it/s]\u001b[A\n",
            " 36% 199/560 [00:19<00:30, 11.96it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:00, 42.41it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 31.32it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 30.17it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 29.66it/s]\u001b[A\n",
            " 79% 22/28 [00:00<00:00, 29.47it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 1.021383285522461, 'eval_accuracy': 0.7424880651502387, 'eval_f1': 0.7262860511180261, 'eval_runtime': 0.9561, 'eval_samples_per_second': 3724.397, 'eval_steps_per_second': 29.285, 'epoch': 1.79}\n",
            " 36% 200/560 [00:20<00:30, 11.96it/s]\n",
            "100% 28/28 [00:00<00:00, 28.41it/s]\u001b[A\n",
            " 53% 299/560 [00:28<00:22, 11.77it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:00, 48.08it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 40.37it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 38.35it/s]\u001b[A\n",
            " 68% 19/28 [00:00<00:00, 37.78it/s]\u001b[A\n",
            " 82% 23/28 [00:00<00:00, 37.73it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.9887887835502625, 'eval_accuracy': 0.7483852850322943, 'eval_f1': 0.7328408536790268, 'eval_runtime': 0.7571, 'eval_samples_per_second': 4703.744, 'eval_steps_per_second': 36.985, 'epoch': 2.68}\n",
            " 54% 300/560 [00:29<00:22, 11.77it/s]\n",
            "100% 28/28 [00:00<00:00, 37.73it/s]\u001b[A\n",
            " 71% 399/560 [00:38<00:13, 11.58it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:00, 40.46it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 37.43it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 37.10it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 37.03it/s]\u001b[A\n",
            " 79% 22/28 [00:00<00:00, 37.43it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.9683045744895935, 'eval_accuracy': 0.7554057848918843, 'eval_f1': 0.7420835674980818, 'eval_runtime': 0.7787, 'eval_samples_per_second': 4573.27, 'eval_steps_per_second': 35.959, 'epoch': 3.57}\n",
            " 71% 400/560 [00:39<00:13, 11.58it/s]\n",
            "100% 28/28 [00:00<00:00, 36.97it/s]\u001b[A\n",
            "{'loss': 1.1444, 'grad_norm': 1.613209843635559, 'learning_rate': 5.357142857142857e-06, 'epoch': 4.46}\n",
            " 89% 500/560 [00:48<00:05, 10.62it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:00, 36.80it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:00, 32.35it/s]\u001b[A\n",
            " 46% 13/28 [00:00<00:00, 31.39it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 30.63it/s]\u001b[A\n",
            " 75% 21/28 [00:00<00:00, 30.06it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.9637570977210999, 'eval_accuracy': 0.7545633249087335, 'eval_f1': 0.7418261246508627, 'eval_runtime': 0.9576, 'eval_samples_per_second': 3718.499, 'eval_steps_per_second': 29.238, 'epoch': 4.46}\n",
            " 89% 500/560 [00:49<00:05, 10.62it/s]\n",
            "100% 28/28 [00:00<00:00, 29.57it/s]\u001b[A\n",
            "{'train_runtime': 65.0108, 'train_samples_per_second': 1095.434, 'train_steps_per_second': 8.614, 'train_loss': 1.1244021006992886, 'epoch': 5.0}\n",
            "100% 560/560 [00:58<00:00,  9.65it/s]\n",
            "100% 28/28 [00:01<00:00, 26.31it/s]\n",
            "{'eval_loss': 0.9637570977210999, 'eval_accuracy': 0.7545633249087335, 'eval_f1': 0.7418261246508627, 'eval_runtime': 1.1322, 'eval_samples_per_second': 3145.342, 'eval_steps_per_second': 24.732, 'epoch': 5.0}\n",
            "\u001b[1;34mwandb\u001b[0m:\n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/BIV_2024/wandb/offline-run-20241116_170643-w69do7do\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241116_170643-w69do7do/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð² onnx"
      ],
      "metadata": {
        "id": "QJ-5AD2f67hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/models_dev/convert_to_onnx.py \\\n",
        "                            --model_path models/trained_model \\\n",
        "                            --onnx_path models/onnx_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or-sJJmHB7T4",
        "outputId": "2dbe2c20-4b64-404f-8af4-0e17f12d5a09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-16 17:08:47.661351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-16 17:08:47.680936: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-16 17:08:47.686958: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-16 17:08:47.702457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-16 17:08:48.820407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ONNX...\n",
            "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n",
            "ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ ONNX: models/onnx_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ÐšÐ²Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"
      ],
      "metadata": {
        "id": "lMMV4HE_6_YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/models_dev/quantize.py --onnx_model_path models/onnx_model/model.onnx \\\n",
        "                                --save_dir models/onnx_model \\\n",
        "                                --max_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duV0Baf3Di_v",
        "outputId": "3e329d59-9522-418c-cede-cee05aa324b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
            "ÐœÐ¾Ð´ÐµÐ»ÑŒ ÐºÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð° Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°: models/onnx_model/model_quantized.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°"
      ],
      "metadata": {
        "id": "9We2zUae-EAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/models_dev/q_infer.py --file_path data/raw/payments_main.tsv \\\n",
        "                 --model_path models/onnx_model/model_quantized.onnx \\\n",
        "                 --tokenizer_path models/onnx_model \\\n",
        "                 --output_file data/predictions.tsv \\\n",
        "                 --batch_size 64 \\\n",
        "                 --max_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNRAAXZKDvh6",
        "outputId": "ce266060-e3cd-4127-f9ad-e86f91501fb7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferencing: 100% 391/391 [02:01<00:00,  3.22it/s]\n",
            "Predictions saved to data/predictions.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r models.zip models/onnx_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-qrw6kMGFg-",
        "outputId": "661ebca7-7d01-477c-fc3b-2be0e08b2975"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/onnx_model/ (stored 0%)\n",
            "  adding: models/onnx_model/tokenizer_config.json (deflated 73%)\n",
            "  adding: models/onnx_model/vocab.txt (deflated 64%)\n",
            "  adding: models/onnx_model/model_quantized.onnx (deflated 34%)\n",
            "  adding: models/onnx_model/model.onnx (deflated 8%)\n",
            "  adding: models/onnx_model/special_tokens_map.json (deflated 80%)\n",
            "  adding: models/onnx_model/config.json (deflated 56%)\n",
            "  adding: models/onnx_model/tokenizer.json (deflated 73%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ²Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸"
      ],
      "metadata": {
        "id": "wlR0weW7-K6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"data/processed/payments_categorized_v3.tsv\", sep='\\t', header=None, names=['date', 'amount', 'description', 'category'])\n",
        "data.drop(index=0, inplace=True)\n",
        "data = data.dropna(subset=['category'])\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, stratify=data['category'], random_state=42)\n",
        "\n",
        "# Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ val_data Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ\n",
        "val_data.to_csv(\"data/processed/val_data.tsv\", sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "68Cwtt4RGzTZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/models_dev/q_infer_val.py \\\n",
        "    --val_data_path data/processed/val_data.tsv \\\n",
        "    --model_path models/onnx_model/model_quantized.onnx \\\n",
        "    --tokenizer_path models/onnx_model \\\n",
        "    --batch_size 64 \\\n",
        "    --max_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi98JL3wI2s2",
        "outputId": "1f802f83-c702-40c3-ea62-563c9b0cbb78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferencing: 100% 56/56 [00:17<00:00,  3.21it/s]\n",
            "True labels: [2, 3, 4, 4, 6, 8, 7, 4, 4, 6]\n",
            "Predictions: [2, 3, 4, 4, 6, 1, 7, 4, 4, 6]\n",
            "Validation Accuracy: 0.7585\n",
            "Validation F1 Score: 0.7454\n"
          ]
        }
      ]
    }
  ]
}